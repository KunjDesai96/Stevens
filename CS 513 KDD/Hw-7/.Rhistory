ann_data<-data.frame(lapply(na.omit(data[,-1]),as.numeric))
idx <- seq (1,nrow(ann_data),by=5)
test<- ann_data[idx,]
training<-ann_data[-idx,]
ann_data<-data.frame(lapply(na.omit(dataSet[,-1]),as.numeric))
rm(list=ls())
data <- read.csv(file.choose())
levels(data$STATUS)
ann_data<-data.frame(lapply(na.omit(data[,-1]),as.numeric))
idx <- seq (1,nrow(ann_data),by=5)
test<- ann_data[idx,]
training<-ann_data[-idx,]
library("neuralnet")
# ?neuralnet()
class(training$STATUS)
net_ann<- neuralnet( STATUS~.,training, hidden=5, threshold=0.01)
prediction <- predict(net_ann,test)
ann_cat<-ifelse(prediction <1.5,1,2)
length(ann_cat)
table(Actual=test$diagnosis,prediction=ann_cat)
wrong<- (test$diagnosis!=ann_cat)
error_rate<-sum(wrong)/length(wrong)
error_rate
ann_cat<-ifelse(prediction <1.5,1,2)
length(ann_cat)
table(Actual=test$STATUS,prediction=ann_cat)
wrong<- (test$STATUS!=ann_cat)
error_rate<-sum(wrong)/length(wrong)
error_rate
summary(ann_data)
## remove all objects
rm(list=ls())
#Library used
library(kknn)
#Reading data file
dataSet<- read.csv(file.choose())
#summary of the data
summary(dataSet)
#Setting seed value
set.seed(123)
# Removing unnecessary columns
dataSet <- subset(dataSet, select = -c(1,4,7,10,11,12,14,16,22))
# Normalization function
mnorm<-function(x)
{z<-((x-min(x))/(max(x)-min(x)))
return (z)}
#Factorizing and normalizing data columns for prediction
dataSet$ANNUAL_RATE <- mnorm(dataSet$ANNUAL_RATE)
dataSet$HRLY_RATE <- mnorm(dataSet$HRLY_RATE)
dataSet$ETHNICITY <- as.factor(as.character(dataSet$ETHNICITY))
dataSet$SEX <- as.numeric(dataSet$SEX)
dataSet$JOB_SATISFACTION <- mnorm(dataSet$JOB_SATISFACTION)
dataSet$AGE <- mnorm(dataSet$AGE)
dataSet$REHIRE <- as.numeric(dataSet$REHIRE)
dataSet$IS_FIRST_JOB <- as.factor(as.character(dataSet$IS_FIRST_JOB))
dataSet$PERFORMANCE_RATING <- mnorm(dataSet$PERFORMANCE_RATING)
dataSet$DISABLED_EMP <- as.factor(as.numeric(dataSet$DISABLED_EMP))
dataSet$DISABLED_VET <- as.factor(as.numeric(dataSet$DISABLED_VET))
dataSet$EDUCATION_LEVEL <- as.factor(as.numeric(dataSet$EDUCATION_LEVEL))
dataSet$PREVYR_1 <- mnorm(dataSet$PREVYR_1)
dataSet$PREVYR_2 <- mnorm(dataSet$PREVYR_2)
dataSet$PREVYR_3 <- mnorm(dataSet$PREVYR_3)
dataSet$PREVYR_4 <- mnorm(dataSet$PREVYR_4)
dataSet$PREVYR_5 <- mnorm(dataSet$PREVYR_5)
#Dividing data into training(70%) and test (30%)
index <- sample(nrow(dataSet), size = floor(.70*nrow(dataSet)), replace = F)
training<-dataSet[index,]
test<-dataSet[-index,]
#Prediction for k = 3
predict_k3 <- kknn(formula=STATUS ~.,training,test,k=3,kernel="rectangular")
fit_3<-fitted(predict_k3)
table(test$STATUS,fit_3)
knn_prev_wrong_3 <- sum(fit_3!=test$STATUS)
knn_prev_error_rate_3 <- knn_prev_wrong_3/length(fit_3)
knn_accuracy_3 <- 1 - knn_prev_error_rate_3
knn_accuracy_3
#Prediction for k = 5
predict_k5 <- kknn(formula=STATUS ~ .,training,test,k=5,kernel="rectangular")
fit_5<-fitted(predict_k5)
table(test$STATUS,fit_5)
knn_prev_wrong_5 <- sum(fit_5!=test$STATUS)
knn_prev_error_rate_5 <- knn_prev_wrong_5/length(fit_5)
knn_accuracy_5 <- 1 - knn_prev_error_rate_5
knn_accuracy_5
#Prediction for k = 10
predict_k10 <- kknn(formula=STATUS ~ .,training,test,k=10,kernel="rectangular")
fit_10<-fitted(predict_k10)
table(test$STATUS,fit_10)
knn_prev_wrong_10 <- sum(fit_10!=test$STATUS)
knn_prev_error_rate_10 <- knn_prev_wrong_10/length(fit_10)
knn_accuracy_10 <- 1 - knn_prev_error_rate_10
knn_accuracy_10
##Prediction for k = 101
predict_k101 <- kknn(formula=STATUS ~ .,training,test,k=101,kernel="rectangular")
fit_101<-fitted(predict_k101)
table(test$STATUS,fit_101)
knn_prev_wrong_101 <- sum(fit_101!=test$STATUS)
knn_prev_error_rate_101 <- knn_prev_wrong_101/length(fit_101)
knn_accuracy_101 <- 1 - knn_prev_error_rate_101
knn_accuracy_101
# Prediction for k = 3 (For HRLY_RATE + PERFORMANCE_RATING +PREVYR_1 + PREVYR_2 + PREVYR_3 + PREVYR_4 + PREVYR_5)
predict_k3 <- kknn(formula=STATUS ~ HRLY_RATE + PERFORMANCE_RATING +PREVYR_1 + PREVYR_2 + PREVYR_3 + PREVYR_4 + PREVYR_5,training,test,k=3,kernel="rectangular")
fit_3<-fitted(predict_k3)
table(test$STATUS,fit_3)
knn_prev_wrong_3 <- sum(fit_3!=test$STATUS)
knn_prev_error_rate_3 <- knn_prev_wrong_3/length(fit_3)
knn_accuracy_3 <- 1 - knn_prev_error_rate_3
knn_accuracy_3
#Prediction for k = 5 (For HRLY_RATE + PERFORMANCE_RATING +PREVYR_1 + PREVYR_2 + PREVYR_3 + PREVYR_4 + PREVYR_5)
predict_k5 <- kknn(formula=STATUS ~ HRLY_RATE + PERFORMANCE_RATING +PREVYR_1 + PREVYR_2 + PREVYR_3 + PREVYR_4 + PREVYR_5,training,test,k=5,kernel="rectangular")
fit_5<-fitted(predict_k5)
table(test$STATUS,fit_5)
knn_prev_wrong_5 <- sum(fit_5!=test$STATUS)
knn_prev_error_rate_5 <- knn_prev_wrong_5/length(fit_5)
knn_accuracy_5 <- 1 - knn_prev_error_rate_5
knn_accuracy_5
#Prediction for k = 10 (For HRLY_RATE + PERFORMANCE_RATING +PREVYR_1 + PREVYR_2 + PREVYR_3 + PREVYR_4 + PREVYR_5)
predict_k10 <- kknn(formula=STATUS ~ HRLY_RATE + PERFORMANCE_RATING +PREVYR_1 + PREVYR_2 + PREVYR_3 + PREVYR_4 + PREVYR_5,training,test,k=10,kernel="rectangular")
fit_10<-fitted(predict_k10)
table(test$STATUS,fit_10)
knn_prev_wrong_10 <- sum(fit_10!=test$STATUS)
knn_prev_error_rate_10 <- knn_prev_wrong_10/length(fit_10)
knn_accuracy_10 <- 1 - knn_prev_error_rate_10
knn_accuracy_10
##Prediction for k = 101 (For HRLY_RATE + PERFORMANCE_RATING +PREVYR_1 + PREVYR_2 + PREVYR_3 + PREVYR_4 + PREVYR_5)
predict_k101 <- kknn(formula=STATUS ~ HRLY_RATE + PERFORMANCE_RATING +PREVYR_1 + PREVYR_2 + PREVYR_3 + PREVYR_4 + PREVYR_5,training,test,k=101,kernel="rectangular")
fit_101<-fitted(predict_k101)
table(test$STATUS,fit_101)
knn_prev_wrong_101 <- sum(fit_101!=test$STATUS)
knn_prev_error_rate_101 <- knn_prev_wrong_101/length(fit_101)
knn_accuracy_101 <- 1 - knn_prev_error_rate_101
knn_accuracy_101
class(training$STATUS)
net_ann<- neuralnet( STATUS~.,training, hidden=5, threshold=0.01)
###########################################################################################
# Company   : Stevens
# Course    : Data Mining
# Purpose   : Use the ANN methodology with five (5) nodes in the hidden layer, to develop a classification model for the STATUS.
# First Name: Kunj
# Last Name : Desai
# ID        : 1044511
# Date      : 04/26/2020
##########################################################################################
## remove all objects
rm(list=ls())
data <- read.csv(file.choose())
### remove all the records with missing value
levels(data$STATUS)
## 1 = B, 2 = M
ann_data<-data.frame(lapply(na.omit(data[,-1]),as.numeric))
idx <- seq (1,nrow(ann_data),by=5)
test<- ann_data[idx,]
training<-ann_data[-idx,]
library("neuralnet")
# ?neuralnet()
class(training$STATUS)
net_ann<- neuralnet( STATUS~.,training, hidden=5, threshold=0.01)
#Plot the neural network
plot(net_ann)
## test should have only the input colum
prediction <- predict(net_ann,test)
ann_cat<-ifelse(prediction <1.5,1,2)
length(ann_cat)
table(Actual=test$STATUS,prediction=ann_cat)
wrong<- (test$STATUS!=ann_cat)
error_rate<-sum(wrong)/length(wrong)
error_rate
###########################################################################################
# Company   : Stevens
# Course    : Data Mining
# Purpose   : Use the ANN methodology with five (5) nodes in the hidden layer, to develop a classification model for the Diagnosis.
# First Name: Kunj
# Last Name : Desai
# ID        : 1044511
# Date      : 04/26/2020
##########################################################################################
## remove all objects
rm(list=ls())
data <- read.csv(file.choose())
### remove all the records with missing value
levels(data$diagnosis)
## 1 = B, 2 = M
ann_data<-data.frame(lapply(na.omit(data[,-1]),as.numeric))
idx <- seq (1,nrow(ann_data),by=5)
test<- ann_data[idx,]
training<-ann_data[-idx,]
library("neuralnet")
# ?neuralnet()
class(training$diagnosis)
net_ann<- neuralnet( diagnosis~.,training, hidden=5, threshold=0.01)
#Plot the neural network
plot(net_ann)
## test should have only the input colum
prediction <- predict(net_ann,test)
ann_cat<-ifelse(prediction <1.5,1,2)
length(ann_cat)
table(Actual=test$diagnosis,prediction=ann_cat)
wrong<- (test$diagnosis!=ann_cat)
error_rate<-sum(wrong)/length(wrong)
error_rate
levels(data$diagnosis)
## remove all objects
rm(list=ls())
data <- read.csv(file.choose())
### remove all the records with missing value
levels(data$STATUS)
ann_data<-data.frame(lapply(na.omit(data[,-1]),as.numeric))
ann_data<-data.frame(lapply(na.omit(data[,-1,-2]),as.numeric))
###########################################################################################
# Company   : Stevens
# Course    : Data Mining
# Purpose   : Use the ANN methodology with five (5) nodes in the hidden layer, to develop a classification model for the STATUS.
# First Name: Kunj
# Last Name : Desai
# ID        : 1044511
# Date      : 04/26/2020
##########################################################################################
## remove all objects
rm(list=ls())
data <- read.csv(file.choose())
### remove all the records with missing value
levels(data$STATUS)
###########################################################################################
# Company   : Stevens
# Course    : Data Mining
# Purpose   : Use the ANN methodology with five (5) nodes in the hidden layer, to develop a classification model for the STATUS.
# First Name: Kunj
# Last Name : Desai
# ID        : 1044511
# Date      : 04/26/2020
##########################################################################################
## remove all objects
rm(list=ls())
data <- read.csv(file.choose())
### remove all the records with missing value
levels(data$STATUS)
ann_data<-data.frame(lapply(na.omit(data[,1]),as.numeric))
## remove all objects
rm(list=ls())
data <- read.csv(file.choose())
### remove all the records with missing value
levels(data$STATUS)
## 1 = B, 2 = M
ann_data<-data.frame(lapply(na.omit(data[,17]),as.numeric))
ann_data<-data.frame(lapply(na.omit(data[,17,23,24,25,26,27]),as.numeric))
ann_data<-data.frame(lapply(na.omit(data[,17,23]),as.numeric))
ann_data<-data.frame(lapply(na.omit(data[,-1]),as.numeric))
## remove all objects
rm(list=ls())
data <- read.csv(file.choose())
### remove all the records with missing value
levels(data$STATUS)
## 1 = B, 2 = M
dataSet <- subset(dataSet, select = -c(1,4,7,10,11,12,14,16,22))
ann_data<-data.frame(lapply(data,as.numeric))
## remove all objects
rm(list=ls())
data <- read.csv(file.choose())
### remove all the records with missing value
levels(data$STATUS)
## 1 = B, 2 = M
data <- subset(data, select = -c(1,4,7,10,11,12,14,16,22))
ann_data<-data.frame(lapply(data,as.numeric))
###########################################################################################
# Company   : Stevens
# Course    : Data Mining
# Purpose   : Use the ANN methodology with five (5) nodes in the hidden layer, to develop a classification model for the STATUS.
# First Name: Kunj
# Last Name : Desai
# ID        : 1044511
# Date      : 04/26/2020
##########################################################################################
## remove all objects
rm(list=ls())
data <- read.csv(file.choose())
### remove all the records with missing value
levels(data$STATUS)
## 1 = B, 2 = M
data <- subset(data, select = -c(1,4,7,10,11,12,14,16,22))
ann_data<-data.frame(lapply(data,as.numeric))
idx <- seq (1,nrow(ann_data),by=5)
test<- ann_data[idx,]
training<-ann_data[-idx,]
library("neuralnet")
# ?neuralnet()
class(training$STATUS)
prediction <- predict(net_ann,test)
ann_cat<-ifelse(prediction <1.5,1,2)
length(ann_cat)
table(Actual=test$STATUS,prediction=ann_cat)
wrong<- (test$STATUS!=ann_cat)
error_rate<-sum(wrong)/length(wrong)
error_rate
net_ann<- neuralnet( STATUS~ HRLY_RATE + PERFORMANCE_RATING +PREVYR_1 + PREVYR_2 + PREVYR_3 + PREVYR_4 + PREVYR_5,training, hidden=5, threshold=0.01)
###########################################################################################
# Company   : Stevens
# Course    : Data Mining
# Purpose   : Use the ANN methodology with five (5) nodes in the hidden layer, to develop a classification model for the STATUS.
# First Name: Kunj
# Last Name : Desai
# ID        : 1044511
# Date      : 04/26/2020
##########################################################################################
## remove all objects
rm(list=ls())
data <- read.csv(file.choose())
### remove all the records with missing value
levels(data$STATUS)
## 1 = B, 2 = M
data <- subset(data, select = -c(1,4,7,10,11,12,14,16,22))
ann_data<-data.frame(lapply(data,as.numeric))
idx <- seq (1,nrow(ann_data),by=5)
test<- ann_data[idx,]
training<-ann_data[-idx,]
library("neuralnet")
# ?neuralnet()
class(training$STATUS)
net_ann<- neuralnet( STATUS~.,training, hidden=5, threshold=0.01)
prediction <- predict(net_ann,test)
ann_cat<-ifelse(prediction <1.5,1,2)
length(ann_cat)
table(Actual=test$STATUS,prediction=ann_cat)
wrong<- (test$STATUS!=ann_cat)
error_rate<-sum(wrong)/length(wrong)
error_rate
plot(net_ann)
## remove all objects
rm(list=ls())
data <- read.csv(file.choose())
names(data)
###########################################################################################
# Company   : Stevens
# Course    : Data Mining
# Purpose   : Use the ANN methodology with five (5) nodes in the hidden layer, to develop a classification model for the STATUS.
# First Name: Kunj
# Last Name : Desai
# ID        : 1044511
# Date      : 04/26/2020
##########################################################################################
## remove all objects
rm(list=ls())
data <- read.csv(file.choose())
names(data)
### remove all the records with missing value
levels(data$STATUS)
## 1 = B, 2 = M
data <- subset(data, select = c(3,21,23,24,25,26,27))
ann_data<-data.frame(lapply(data,as.numeric))
idx <- seq (1,nrow(ann_data),by=5)
test<- ann_data[idx,]
training<-ann_data[-idx,]
library("neuralnet")
# ?neuralnet()
class(training$STATUS)
net_ann<- neuralnet( STATUS~.,training, hidden=5, threshold=0.01)
#Plot the neural network
plot(net_ann)
## test should have only the input colum
prediction <- predict(net_ann,test)
ann_cat<-ifelse(prediction <1.5,1,2)
length(ann_cat)
table(Actual=test$STATUS,prediction=ann_cat)
wrong<- (test$STATUS!=ann_cat)
error_rate<-sum(wrong)/length(wrong)
error_rate
###########################################################################################
# Company   : Stevens
# Course    : Data Mining
# Purpose   : Use the ANN methodology with five (5) nodes in the hidden layer, to develop a classification model for the STATUS.
# First Name: Kunj
# Last Name : Desai
# ID        : 1044511
# Date      : 04/26/2020
##########################################################################################
## remove all objects
rm(list=ls())
data <- read.csv(file.choose())
names(data)
### remove all the records with missing value
levels(data$STATUS)
## 1 = B, 2 = M
data <- subset(data, select = c(3,21,23,24,25,26,27))
ann_data<-data.frame(lapply(data,as.numeric))
idx <- seq (1,nrow(ann_data),by=5)
test<- ann_data[idx,]
training<-ann_data[-idx,]
library("neuralnet")
# ?neuralnet()
class(training$STATUS)
net_ann<- neuralnet( STATUS~.,training, hidden=5, threshold=0.01)
###########################################################################################
# Company   : Stevens
# Course    : Data Mining
# Purpose   : Use the ANN methodology with five (5) nodes in the hidden layer, to develop a classification model for the STATUS.
# First Name: Kunj
# Last Name : Desai
# ID        : 1044511
# Date      : 04/26/2020
##########################################################################################
## remove all objects
rm(list=ls())
data <- read.csv(file.choose())
names(data)
### remove all the records with missing value
levels(data$STATUS)
## 1 = B, 2 = M
data <- subset(data, select = c(3,21,23,24,25,26,27))
ann_data<-data
idx <- seq (1,nrow(ann_data),by=5)
test<- ann_data[idx,]
training<-ann_data[-idx,]
library("neuralnet")
# ?neuralnet()
class(training$STATUS)
net_ann<- neuralnet( STATUS~.,training, hidden=5, threshold=0.01)
###########################################################################################
# Company   : Stevens
# Course    : Data Mining
# Purpose   : Use the ANN methodology with five (5) nodes in the hidden layer, to develop a classification model for the STATUS.
# First Name: Kunj
# Last Name : Desai
# ID        : 1044511
# Date      : 04/26/2020
##########################################################################################
## remove all objects
rm(list=ls())
data <- read.csv(file.choose())
### remove all the records with missing value
levels(data$STATUS)
## 1 = B, 2 = M
data <- subset(data, select = -c(1,4,7,10,11,12,14,16,22))
ann_data<-data.frame(lapply(data,as.numeric))
idx <- seq (1,nrow(ann_data),by=5)
test<- ann_data[idx,]
training<-ann_data[-idx,]
library("neuralnet")
# ?neuralnet()
class(training$STATUS)
net_ann<- neuralnet( STATUS~.,training, hidden=5, threshold=0.01)
#Plot the neural network
plot(net_ann)
## test should have only the input colum
prediction <- predict(net_ann,test)
ann_cat<-ifelse(prediction <1.5,1,2)
length(ann_cat)
table(Actual=test$STATUS,prediction=ann_cat)
wrong<- (test$STATUS!=ann_cat)
error_rate<-sum(wrong)/length(wrong)
error_rate
###########################################################################################
# Company   : Stevens
# Course    : Data Mining
# Purpose   : Use the ANN methodology with five (5) nodes in the hidden layer, to develop a classification model for the STATUS.
# First Name: Kunj
# Last Name : Desai
# ID        : 1044511
# Date      : 04/26/2020
##########################################################################################
## remove all objects
rm(list=ls())
data <- read.csv(file.choose())
### remove all the records with missing value
levels(data$STATUS)
## 1 = B, 2 = M
data <- subset(data, select = -c(1,4,7,10,11,12,14,16,22))
ann_data<-data.frame(lapply(data,as.numeric))
idx <- seq (1,nrow(ann_data),by=5)
test<- ann_data[idx,]
training<-ann_data[-idx,]
library("neuralnet")
# ?neuralnet()
class(training$STATUS)
net_ann<- neuralnet( STATUS~.,training, hidden=5, threshold=0.01)
#Plot the neural network
plot(net_ann)
## test should have only the input colum
prediction <- predict(net_ann,test)
ann_cat<-ifelse(prediction <1.5,1,2)
length(ann_cat)
table(Actual=test$STATUS,prediction=ann_cat)
wrong<- (test$STATUS!=ann_cat)
error_rate<-sum(wrong)/length(wrong)
accuracy = 1-error_rate
accuracy
