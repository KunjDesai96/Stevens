###########################################################################################
# Company   : Stevens
# Course    : Data Mining
# Purpose   : 2 Use the Random Forest methodology to develop a classification model for the Admission_cat dataset using gre, gpa and the rank variables as predictors.
# First Name: Kunj
# Last Name : Desai
# ID        : 1044511
# Date      : 05/13/2020
##########################################################################################
##Step O - Remove all objects
rm(list=ls())
#Step 0 - Choosing the data
data <- read.csv(file.choose(),colClasses = c("NULL", rep('factor',4)))
#data$GRE <- as.factor(as.numeric(data$GRE))
#data$GPA <- as.factor(as.numeric(data$GPA))
View(data)
#Step 1 - Install Packages
#install.packages('randomForest')
library('C50')
set.seed(123)
#Step 2 - Dividing data into Test and Training datasets
idx<-sort(sample(nrow(data),round(.30*nrow(data))))
trainingData<-data[-idx,]
testData<-data[idx,]
#Step 3 - Creaitng the model
C50_model <- C5.0(ADMIT~.,data=trainingData )
summary(C50_model )
plot(C50_model)
#Step 4 - Predicting values
C50_predict<-predict( C50_model ,testData , type="class" )
table(actual=testData$ADMIT,C50=C50_predict)
str(C50_predict)
wrong<- (testData$ADMIT!=C50_predict)
#Step 6 - Finding accuracy and error rate
error_rate<-sum(wrong)/length(wrong)
error_rate
accuracy = (1-error_rate)
accuracy
###########################################################################################
# Company   : Stevens
# Course    : Data Mining
# Purpose   : Answers 1.1 and 1.2
# First Name: Kunj
# Last Name : Desai
# ID        : 1044511
# Date      : 05/13/2020
##########################################################################################
#Step 0 - Remove all objects
rm(list=ls())
#Step 0 - Choosing the data
admission_dataSet <- read.csv(file.choose(),na.strings = '?')
#Step 1 - Viewing and summarizing the data
View(admission_dataSet)
summary(admission_dataSet)
table(admission_dataSet$ADMIT)
# Step 2 - Factorizing ADMIT and labeling levels 0 = "NOT ADMIT" and level 1 = "ADMIT"
admission_dataSet$ADMIT <- factor(admission_dataSet$ADMIT, levels = c(0, 1), labels = c('Not-Admit', 'Admit'))
admission_dataSet<-admission_dataSet[-1]
# Step 3 - 1.1 Using the kmeans clustering method to create two clusters for the Admission dataset using gre and gpa as clustering variables.
kmeans_data<- kmeans(admission_dataSet[,c(2, 3)], 2, nstart = 10)
kmeans_data$cluster
table(kmeans_data$cluster,admission_dataSet$ADMIT)
# Step 4 - 1.2 Using the hierarchical clustering method to create two clusters for the Admission dataset using gre and gpa as clustering variables.
admission_dist<-dist(admission_dataSet[,c (2, 3)])
hclust_results<-hclust(admission_dist)
plot(hclust_results)
hclust_2<-cutree(hclust_results,2)
table(hclust_2,admission_dataSet$ADMIT)
##Step O - Remove all objects
rm(list=ls())
###########################################################################################
# Company   : Stevens
# Course    : Data Mining
# Purpose   : 2 Use the Random Forest methodology to develop a classification model for the Admission_cat dataset using gre, gpa and the rank variables as predictors.
# First Name: Kunj
# Last Name : Desai
# ID        : 1044511
# Date      : 05/13/2020
##########################################################################################
##Step O - Remove all objects
rm(list=ls())
#Step 0 - Choosing the data
data <- read.csv(file.choose(),colClasses = c("NULL", rep('factor',4)))
View(data)
#Step 1 - Install Packages
#install.packages('randomForest')
library(randomForest)
set.seed(123)
#Step 2 - Cleaning the data
admission_dataSet <- na.omit(data)
admission_dataSet
summary(admission_dataSet)
#Step 3 - Dividing data into Test and Training datasets
idx<-sort(sample(nrow(admission_dataSet),round(.30*nrow(admission_dataSet))))
training<-data[-idx,]
test<-data[idx,]
#Step 4 - Creaitng the model
fit <- randomForest( ADMIT~., data=training, importance=TRUE, ntree=1000)
importance(fit)
varImpPlot(fit)
#Step 5 - Predicting values
Prediction <- predict(fit, test)
table(actual=test$ADMIT,Prediction)
#Step 6 - Finding accuracy and error rate
wrong<- (test$ADMIT!=Prediction )
error_rate<-sum(wrong)/length(wrong)
error_rate
accuracy = (1-error_rate) * 100
accuracy
###########################################################################################
# Company   : Stevens
# Course    : Data Mining
# Purpose   : 2 Use the Random Forest methodology to develop a classification model for the Admission_cat dataset using gre, gpa and the rank variables as predictors.
# First Name: Kunj
# Last Name : Desai
# ID        : 1044511
# Date      : 05/13/2020
##########################################################################################
##Step O - Remove all objects
rm(list=ls())
#Step 0 - Choosing the data
data <- read.csv(file.choose(),colClasses = c("NULL", rep('factor',4)))
View(data)
#Step 1 - Install Packages
#install.packages('randomForest')
library(randomForest)
set.seed(123)
#Step 2 - Cleaning the data
admission_dataSet <- na.omit(data)
admission_dataSet
summary(admission_dataSet)
#Step 3 - Dividing data into Test and Training datasets
idx<-sort(sample(nrow(admission_dataSet),round(.30*nrow(admission_dataSet))))
training<-data[-idx,]
test<-data[idx,]
#Step 4 - Creaitng the model
fit <- randomForest( ADMIT~., data=training, importance=TRUE, ntree=1000)
importance(fit)
varImpPlot(fit)
#Step 5 - Predicting values
Prediction <- predict(fit, test)
table(actual=test$ADMIT,Prediction)
#Step 6 - Finding accuracy and error rate
wrong<- (test$ADMIT!=Prediction )
error_rate<-sum(wrong)/length(wrong)
error_rate
accuracy = (1-error_rate) * 100
accuracy
###########################################################################################
# Company   : Stevens
# Course    : Data Mining
# Purpose   : Answers 1.1 and 1.2
# First Name: Kunj
# Last Name : Desai
# ID        : 1044511
# Date      : 05/13/2020
##########################################################################################
#Step 0 - Remove all objects
rm(list=ls())
#Step 0 - Choosing the data
admission_dataSet <- read.csv(file.choose(),na.strings = '?')
#Step 1 - Viewing and summarizing the data
View(admission_dataSet)
summary(admission_dataSet)
table(admission_dataSet$ADMIT)
# Step 2 - Factorizing ADMIT and labeling levels 0 = "NOT ADMIT" and level 1 = "ADMIT"
admission_dataSet$ADMIT <- factor(admission_dataSet$ADMIT, levels = c(0, 1), labels = c('Not-Admit', 'Admit'))
admission_dataSet<-admission_dataSet[-1]
# Step 3 - 1.1 Using the kmeans clustering method to create two clusters for the Admission dataset using gre and gpa as clustering variables.
kmeans_data<- kmeans(admission_dataSet[,c(2, 3)], 2, nstart = 10)
kmeans_data$cluster
table(kmeans_data$cluster,admission_dataSet$ADMIT)
# Step 4 - 1.2 Using the hierarchical clustering method to create two clusters for the Admission dataset using gre and gpa as clustering variables.
admission_dist<-dist(admission_dataSet[,c (2, 3)])
hclust_results<-hclust(admission_dist)
plot(hclust_results)
hclust_2<-cutree(hclust_results,2)
table(hclust_2,admission_dataSet$ADMIT)
###########################################################################################
# Company   : Stevens
# Course    : Data Mining
# Purpose   : 2 Use the Random Forest methodology to develop a classification model for the Admission_cat dataset using gre, gpa and the rank variables as predictors.
# First Name: Kunj
# Last Name : Desai
# ID        : 1044511
# Date      : 05/13/2020
##########################################################################################
##Step O - Remove all objects
rm(list=ls())
#Step 0 - Choosing the data
data <- read.csv(file.choose(),colClasses = c("NULL", rep('factor',4)))
View(data)
#Step 1 - Install Packages
#install.packages('randomForest')
library(randomForest)
set.seed(123)
#Step 2 - Cleaning the data
admission_dataSet <- na.omit(data)
admission_dataSet
summary(admission_dataSet)
#Step 3 - Dividing data into Test and Training datasets
idx<-sort(sample(nrow(admission_dataSet),round(.30*nrow(admission_dataSet))))
training<-data[-idx,]
test<-data[idx,]
#Step 4 - Creaitng the model
fit <- randomForest( ADMIT~., data=training, importance=TRUE, ntree=1000)
importance(fit)
varImpPlot(fit)
#Step 5 - Predicting values
Prediction <- predict(fit, test)
table(actual=test$ADMIT,Prediction)
#Step 6 - Finding accuracy and error rate
wrong<- (test$ADMIT!=Prediction )
error_rate<-sum(wrong)/length(wrong)
error_rate
accuracy = (1-error_rate) * 100
accuracy
###########################################################################################
# Company   : Stevens
# Course    : Data Mining
# Purpose   : 2 Use the Random Forest methodology to develop a classification model for the Admission_cat dataset using gre, gpa and the rank variables as predictors.
# First Name: Kunj
# Last Name : Desai
# ID        : 1044511
# Date      : 05/13/2020
##########################################################################################
##Step O - Remove all objects
rm(list=ls())
#Step 0 - Choosing the data
data <- read.csv(file.choose(),colClasses = c("NULL", rep('factor',4)))
#data$GRE <- as.factor(as.numeric(data$GRE))
#data$GPA <- as.factor(as.numeric(data$GPA))
View(data)
#Step 1 - Install Packages
#install.packages('randomForest')
library('C50')
set.seed(123)
#Step 2 - Dividing data into Test and Training datasets
idx<-sort(sample(nrow(data),round(.30*nrow(data))))
trainingData<-data[-idx,]
testData<-data[idx,]
#Step 3 - Creaitng the model
C50_model <- C5.0(ADMIT~.,data=trainingData )
summary(C50_model )
plot(C50_model)
#Step 4 - Predicting values
C50_predict<-predict( C50_model ,testData , type="class" )
table(actual=testData$ADMIT,C50=C50_predict)
str(C50_predict)
wrong<- (testData$ADMIT!=C50_predict)
#Step 6 - Finding accuracy and error rate
error_rate<-sum(wrong)/length(wrong)
error_rate
accuracy = (1-error_rate) * 100
accuracy
###########################################################################################
# Company   : Stevens
# Course    : Data Mining
# Purpose   : 2 Use the Random Forest methodology to develop a classification model for the Admission_cat dataset using gre, gpa and the rank variables as predictors.
# First Name: Kunj
# Last Name : Desai
# ID        : 1044511
# Date      : 05/13/2020
##########################################################################################
##Step O - Remove all objects
rm(list=ls())
#Step 0 - Choosing the data
data <- read.csv(file.choose(),colClasses = c("NULL", rep('factor',4)))
#data$GRE <- as.factor(as.numeric(data$GRE))
#data$GPA <- as.factor(as.numeric(data$GPA))
View(data)
#Step 1 - Install Packages
#install.packages('randomForest')
library('C50')
set.seed(123)
#Step 2 - Dividing data into Test and Training datasets
idx<-sort(sample(nrow(data),round(.30*nrow(data))))
trainingData<-data[-idx,]
testData<-data[idx,]
#Step 3 - Creaitng the model
C50_model <- C5.0(ADMIT~.,data=trainingData )
summary(C50_model )
plot(C50_model)
#Step 4 - Predicting values
C50_predict<-predict( C50_model ,testData , type="class" )
table(actual=testData$ADMIT,C50=C50_predict)
str(C50_predict)
wrong<- (testData$ADMIT!=C50_predict)
#Step 6 - Finding accuracy and error rate
error_rate<-sum(wrong)/length(wrong)
error_rate
accuracy = (1-error_rate) * 100
accuracy
###########################################################################################
# Company   : Stevens
# Course    : Data Mining
# Purpose   : 2 Use the Random Forest methodology to develop a classification model for the Admission_cat dataset using gre, gpa and the rank variables as predictors.
# First Name: Kunj
# Last Name : Desai
# ID        : 1044511
# Date      : 05/13/2020
##########################################################################################
##Step O - Remove all objects
rm(list=ls())
#Step 0 - Choosing the data
data <- read.csv(file.choose(),colClasses = c("NULL", rep('factor',4)))
#data$GRE <- as.factor(as.numeric(data$GRE))
#data$GPA <- as.factor(as.numeric(data$GPA))
View(data)
#Step 1 - Install Packages
#install.packages('randomForest')
library('C50')
set.seed(123)
#Step 2 - Dividing data into Test and Training datasets
idx<-sort(sample(nrow(data),round(.30*nrow(data))))
trainingData<-data[-idx,]
testData<-data[idx,]
#Step 3 - Creaitng the model
C50_model <- C5.0(ADMIT~.,data=trainingData )
summary(C50_model )
plot(C50_model)
#Step 4 - Predicting values
C50_predict<-predict( C50_model ,testData , type="class" )
table(actual=testData$ADMIT,C50=C50_predict)
str(C50_predict)
wrong<- (testData$ADMIT!=C50_predict)
#Step 6 - Finding accuracy and error rate
error_rate<-sum(wrong)/length(wrong)
error_rate
accuracy = (1-error_rate) * 100
accuracy
##Step O - Remove all objects
rm(list=ls())
###########################################################################################
# Company   : Stevens
# Course    : Data Mining
# Purpose   : 2. Use the Random Forest methodology to develop a classification model for the Admission_cat dataset using gre, gpa and the rank variables as predictors.
# First Name: Kunj
# Last Name : Desai
# ID        : 1044511
# Date      : 05/13/2020
##########################################################################################
##Step O - Remove all objects
rm(list=ls())
#Step 0 - Choosing the data
data <- read.csv(file.choose(),colClasses = c("NULL", rep('factor',4)))
View(data)
#Step 1 - Install Packages
#install.packages('randomForest')
library(randomForest)
set.seed(123)
#Step 2 - Cleaning the data
admission_dataSet <- na.omit(data)
admission_dataSet
summary(admission_dataSet)
#Step 3 - Dividing data into Test and Training datasets
idx<-sort(sample(nrow(admission_dataSet),round(.30*nrow(admission_dataSet))))
training<-data[-idx,]
test<-data[idx,]
#Step 4 - Creaitng the model
fit <- randomForest( ADMIT~., data=training, importance=TRUE, ntree=1000)
importance(fit)
varImpPlot(fit)
#Step 5 - Predicting values
Prediction <- predict(fit, test)
table(actual=test$ADMIT,Prediction)
#Step 6 - Finding accuracy and error rate
wrong<- (test$ADMIT!=Prediction )
error_rate<-sum(wrong)/length(wrong)
error_rate
accuracy = (1-error_rate) * 100
accuracy
###########################################################################################
# Company   : Stevens
# Course    : Data Mining
# Purpose   : Answers 1.1 and 1.2
# First Name: Kunj
# Last Name : Desai
# ID        : 1044511
# Date      : 05/13/2020
##########################################################################################
#Step 0 - Remove all objects
rm(list=ls())
#Step 0 - Choosing the data
admission_dataSet <- read.csv(file.choose(),na.strings = '?')
#Step 1 - Viewing and summarizing the data
View(admission_dataSet)
summary(admission_dataSet)
table(admission_dataSet$ADMIT)
# Step 2 - Factorizing ADMIT and labeling levels 0 = "NOT ADMIT" and level 1 = "ADMIT"
admission_dataSet$ADMIT <- factor(admission_dataSet$ADMIT, levels = c(0, 1), labels = c('Not-Admit', 'Admit'))
admission_dataSet<-admission_dataSet[-1]
# Step 3 - 1.1 Using the kmeans clustering method to create two clusters for the Admission dataset using gre and gpa as clustering variables.
kmeans_data<- kmeans(admission_dataSet[,c(2, 3)], 2, nstart = 10)
kmeans_data$cluster
table(kmeans_data$cluster,admission_dataSet$ADMIT)
# Step 4 - 1.2 Using the hierarchical clustering method to create two clusters for the Admission dataset using gre and gpa as clustering variables.
admission_dist<-dist(admission_dataSet[,c (2, 3)])
hclust_results<-hclust(admission_dist)
plot(hclust_results)
hclust_2<-cutree(hclust_results,2)
table(hclust_2,admission_dataSet$ADMIT)
